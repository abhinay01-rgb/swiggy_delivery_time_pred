Train:
  model_name: "LightGBM"  # Options: XGBoost, RandomForest, LightGBM, DecisionTree

  XGBoost:
    n_estimators: 100
    learning_rate: 0.1
    max_depth: 6
    subsample: 1.0
    colsample_bytree: 1.0
    gamma: 0
    reg_alpha: 0
    reg_lambda: 1
    random_state: 48

  RandomForest:
    n_estimators: 100
    max_depth: 10
    random_state: 48

  LightGBM:
    n_estimators: 100
    learning_rate: 0.1
    num_leaves: 31
    max_depth: -1
    random_state: 48

  DecisionTree:
    max_depth: 10
    criterion: "mse"
    random_state: 48

Data_Preparation:
  random_state: 48
  test_size: 0.3
